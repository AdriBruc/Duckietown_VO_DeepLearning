{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepVO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing script for colaborate ultra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check GPU and Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "%matplotlib !pip uninstall -y Pillow\n",
    "\n",
    "# install the new one\n",
    "!pip install Pillow==5.3.0\n",
    "# import the new one\n",
    "import PIL\n",
    "print(PIL.PILLOW_VERSION)inline\n",
    "\n",
    " http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch\n",
    "\n",
    "# load tqdm\n",
    "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import gzip\n",
    "import io\n",
    "import os\n",
    "import os.path\n",
    "import time\n",
    "import copy\n",
    "import shutil\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn.init import calculate_gain\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mount data folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={\"datapath\":'drive/My Drive/VOdata/alex_3small_loops', \"checkpoint_path\":'./Checkpoint',\n",
    "       \"checkpoint\":None,\n",
    "       \"bsize\":32, \"lr\":0.001, \"weight_decay\":1e-4, \"trajectory_length\":5, \"dropout_p\":0.85,\n",
    "       \"resize\":64, \"K\":100, \"epochs\"=100, \"patience\"=40}\n",
    "\n",
    "if not os.path.exists(args[\"checkpoint_path\"]): os.makedirs(args[\"checkpoint_path\"]) \n",
    "\n",
    "model = DeepVONet(args[\"resize\"], args[\"resize\"], args[\"dropout_p\"])\n",
    "\n",
    "print(\"Number of parameters:\", human_format(count_parameters(model)))\n",
    "print(\"Number of parameter bytes:\", human_format(32*count_parameters(model)))\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "\n",
    "if USE_GPU:\n",
    "    model.cuda()\n",
    "\n",
    "if args[\"checkpoint\"] is not None:\n",
    "    the_checkpoint = torch.load(args[\"checkpoint\"])\n",
    "    model.load_state_dict(the_checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, logs, args_ = train(model, preprocess, args, epochs=args[\"epochs\"], patience=args[\"patience\"])\n",
    "plot_train_valid(logs, args_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, predicted_test_relative_poses = test(best_model, preprocess, args_)\n",
    "test_data = DeepVOdata(datapath=args[\"datapath\"], trajectory_length=args[\"trajectory_length\"],\n",
    "                           transform=preprocess, kind='test')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
